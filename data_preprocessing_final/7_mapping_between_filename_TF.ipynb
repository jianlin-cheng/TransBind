{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique features: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "file_path = '/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/1.sorted'\n",
    "\n",
    "# Read the file into a DataFrame\n",
    "df = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "\n",
    "# Assuming the columns correspond to: \n",
    "# chr, start, end, feature, chromosome_2, start_2, end_2, dot, value_1, dot_2, score, minus, value_2, score_2\n",
    "# You can modify these column names as needed based on the actual structure of your file\n",
    "df.columns = ['chromosome', 'start', 'end', 'feature', 'chromosome_2', 'start_2', 'end_2', 'dot', \n",
    "              'value_1', 'dot_2', 'score', 'minus', 'value_2', 'score_2']\n",
    "\n",
    "# Get the unique features\n",
    "unique_features = df['feature'].unique()\n",
    "\n",
    "# Output the number of unique features\n",
    "print(f\"Number of unique features: {len(unique_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the TF and cell type list to /bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_celltype_list.csv\n",
      "Number of unique transcription factors: 171\n",
      "Number of unique cell types: 91\n",
      "\n",
      "Unique transcription factors (sorted alphabetically):\n",
      "- AP-2alpha\n",
      "- AP-2gamma\n",
      "- ARID3A\n",
      "- ATF1\n",
      "- ATF2\n",
      "- ATF3\n",
      "- BAF155\n",
      "- BAF170\n",
      "- BATF\n",
      "- BCL11A\n",
      "- BCL3\n",
      "- BCLAF1\n",
      "- BDP1\n",
      "- BHLHE40\n",
      "- BRCA1\n",
      "- BRF1\n",
      "- BRF2\n",
      "- Bach1\n",
      "- Brg1\n",
      "- CBX3\n",
      "- CCNT2\n",
      "- CEBPB\n",
      "- CEBPD\n",
      "- CHD1\n",
      "- CHD2\n",
      "- COREST\n",
      "- CREB1\n",
      "- CTCF\n",
      "- CTCFL\n",
      "- CtBP2\n",
      "- E2F1\n",
      "- E2F4\n",
      "- E2F6\n",
      "- EBF1\n",
      "- ELF1\n",
      "- ELK1\n",
      "- ELK4\n",
      "- ERRA\n",
      "- ERalpha_a\n",
      "- ETS1\n",
      "- EZH2\n",
      "- Egr-1\n",
      "- FOSL1\n",
      "- FOSL2\n",
      "- FOXA1\n",
      "- FOXA2\n",
      "- FOXM1\n",
      "- FOXP2\n",
      "- GABP\n",
      "- GATA-1\n",
      "- GATA-2\n",
      "- GATA2\n",
      "- GATA3\n",
      "- GR\n",
      "- GRp20\n",
      "- GTF2B\n",
      "- GTF2F1\n",
      "- HA-E2F1\n",
      "- HDAC1\n",
      "- HDAC2\n",
      "- HDAC6\n",
      "- HMGN3\n",
      "- HNF4A\n",
      "- HNF4G\n",
      "- HSF1\n",
      "- IKZF1\n",
      "- IRF1\n",
      "- IRF3\n",
      "- IRF4\n",
      "- Ini1\n",
      "- JARID1A\n",
      "- JunD\n",
      "- KAP1\n",
      "- MAZ\n",
      "- MBD4\n",
      "- MEF2A\n",
      "- MEF2C\n",
      "- MTA3\n",
      "- MYBL2\n",
      "- MafF\n",
      "- MafK\n",
      "- Max\n",
      "- Mxi1\n",
      "- NANOG\n",
      "- NELFe\n",
      "- NF-E2\n",
      "- NF-YA\n",
      "- NF-YB\n",
      "- NFATC1\n",
      "- NFIC\n",
      "- NFKB\n",
      "- NR2F2\n",
      "- NRSF\n",
      "- Nrf1\n",
      "- PAX5-C20\n",
      "- PAX5-N19\n",
      "- PGC1A\n",
      "- PHF8\n",
      "- PLU1\n",
      "- PML\n",
      "- POU2F2\n",
      "- POU5F1\n",
      "- PRDM1\n",
      "- PU.1\n",
      "- Pbx3\n",
      "- Pol2\n",
      "- Pol2-4H8\n",
      "- Pol3\n",
      "- RBBP5\n",
      "- RFX5\n",
      "- RPC155\n",
      "- RUNX3\n",
      "- RXRA\n",
      "- Rad21\n",
      "- SAP30\n",
      "- SETDB1\n",
      "- SIN3A\n",
      "- SIRT6\n",
      "- SIX5\n",
      "- SMC3\n",
      "- SP1\n",
      "- SP2\n",
      "- SP4\n",
      "- SPT20\n",
      "- SREBP1\n",
      "- SRF\n",
      "- STAT1\n",
      "- STAT2\n",
      "- STAT3\n",
      "- STAT5A\n",
      "- SUZ12\n",
      "- Sin3Ak-20\n",
      "- TAF1\n",
      "- TAF7\n",
      "- TAL1\n",
      "- TBLR1\n",
      "- TBP\n",
      "- TCF12\n",
      "- TCF3\n",
      "- TCF7L2\n",
      "- TCF7L2_C9B9\n",
      "- TEAD4\n",
      "- TFIIIC-110\n",
      "- THAP1\n",
      "- TR4\n",
      "- TRIM28\n",
      "- UBF\n",
      "- UBTF\n",
      "- USF-1\n",
      "- USF1\n",
      "- USF2\n",
      "- WHIP\n",
      "- YY1\n",
      "- ZBTB33\n",
      "- ZBTB7A\n",
      "- ZEB1\n",
      "- ZKSCAN1\n",
      "- ZNF217\n",
      "- ZNF263\n",
      "- ZNF274\n",
      "- ZZZ3\n",
      "- Znf143\n",
      "- c-Fos\n",
      "- c-Jun\n",
      "- c-Myc\n",
      "- eGFP-FOS\n",
      "- eGFP-GATA2\n",
      "- eGFP-HDAC8\n",
      "- eGFP-JunB\n",
      "- eGFP-JunD\n",
      "- p300\n",
      "\n",
      "Unique cell types (sorted alphabetically):\n",
      "- A549\n",
      "- AG04449\n",
      "- AG04450\n",
      "- AG09309\n",
      "- AG09319\n",
      "- AG10803\n",
      "- AoAF\n",
      "- BE2_C\n",
      "- BJ\n",
      "- Caco-2\n",
      "- Dnd41\n",
      "- ECC-1\n",
      "- Fibrobl\n",
      "- GM06990\n",
      "- GM08714\n",
      "- GM10847\n",
      "- GM12801\n",
      "- GM12864\n",
      "- GM12865\n",
      "- GM12872\n",
      "- GM12873\n",
      "- GM12874\n",
      "- GM12875\n",
      "- GM12878\n",
      "- GM12891\n",
      "- GM12892\n",
      "- GM15510\n",
      "- GM18505\n",
      "- GM18526\n",
      "- GM18951\n",
      "- GM19099\n",
      "- GM19193\n",
      "- GM19238\n",
      "- GM19239\n",
      "- GM19240\n",
      "- Gliobla\n",
      "- H1-hESC\n",
      "- HA-sp\n",
      "- HAc\n",
      "- HBMEC\n",
      "- HCFaa\n",
      "- HCM\n",
      "- HCPEpiC\n",
      "- HCT-116\n",
      "- HEEpiC\n",
      "- HEK293\n",
      "- HEK293-T-REx\n",
      "- HFF\n",
      "- HFF-Myc\n",
      "- HL-60\n",
      "- HMEC\n",
      "- HMF\n",
      "- HPAF\n",
      "- HPF\n",
      "- HRE\n",
      "- HRPEpiC\n",
      "- HSMM\n",
      "- HSMMtube\n",
      "- HUVEC\n",
      "- HVMF\n",
      "- HeLa-S3\n",
      "- HepG2\n",
      "- IMR90\n",
      "- K562\n",
      "- MCF-7\n",
      "- MCF10A-Er-Src\n",
      "- NB4\n",
      "- NH-A\n",
      "- NHDF-Ad\n",
      "- NHDF-neo\n",
      "- NHEK\n",
      "- NHLF\n",
      "- NT2-D1\n",
      "- Osteobl\n",
      "- PANC-1\n",
      "- PBDE\n",
      "- PBDEFetal\n",
      "- PFSK-1\n",
      "- ProgFib\n",
      "- RPTEC\n",
      "- Raji\n",
      "- SAEC\n",
      "- SH-SY5Y\n",
      "- SK-N-MC\n",
      "- SK-N-SH\n",
      "- SK-N-SH_RA\n",
      "- T-47D\n",
      "- U2OS\n",
      "- U87\n",
      "- WERI-Rb-1\n",
      "- WI-38\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# Directory where the metadata file is located\n",
    "metadata_file = '/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/downloads/wgEncodeAwgTfbsUniform/files.txt'  # Update this path\n",
    "\n",
    "# Lists to store extracted TF and cell type\n",
    "tf_celltype_list = []\n",
    "unique_tfs = set()\n",
    "unique_celltypes = set()\n",
    "filename_tf_celltype_map = {}\n",
    "\n",
    "# Read the metadata file and extract TF and cell type\n",
    "def parse_metadata(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Metadata file not found: {file_path}\")\n",
    "        return {}\n",
    "    \n",
    "    result = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Skip empty lines\n",
    "            if not line.strip():\n",
    "                continue\n",
    "                \n",
    "            # Parse the line\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "                \n",
    "            filename = parts[0]\n",
    "            metadata = parts[1]\n",
    "            \n",
    "            # Extract antibody (TF) and cell from metadata\n",
    "            antibody_match = re.search(r'antibody=([^;]+)', metadata)\n",
    "            cell_match = re.search(r'cell=([^;]+)', metadata)\n",
    "            \n",
    "            if antibody_match and cell_match:\n",
    "                antibody = antibody_match.group(1)\n",
    "                cell = cell_match.group(1)\n",
    "                \n",
    "                # Clean up antibody name\n",
    "                # Remove any part after underscore or parentheses (like \"_(39875)\")\n",
    "                tf = re.sub(r'_\\([^)]+\\)|\\([^)]+\\)', '', antibody)\n",
    "                \n",
    "                # Store in result dictionary\n",
    "                result[filename] = (tf, cell)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Parse the metadata file\n",
    "metadata_dict = parse_metadata(metadata_file)\n",
    "\n",
    "# Extract the TF and cell type information\n",
    "for filename, (tf, cell) in metadata_dict.items():\n",
    "    # Add to the list and sets\n",
    "    tf_celltype_list.append((tf, cell, filename))\n",
    "    unique_tfs.add(tf)\n",
    "    unique_celltypes.add(cell)\n",
    "\n",
    "# Sort by TF name alphabetically\n",
    "tf_celltype_list.sort(key=lambda x: x[0])\n",
    "\n",
    "# Path to save the CSV\n",
    "output_csv = '/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_celltype_list.csv'\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_csv, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Transcription Factor', 'Cell Type', 'Filename'])  # Header\n",
    "    for tf, cell, filename in tf_celltype_list:\n",
    "        writer.writerow([tf, cell, filename])\n",
    "\n",
    "# Print counts and debug information\n",
    "print(f\"Saved the TF and cell type list to {output_csv}\")\n",
    "print(f\"Number of unique transcription factors: {len(unique_tfs)}\")\n",
    "print(f\"Number of unique cell types: {len(unique_celltypes)}\")\n",
    "print(\"\\nUnique transcription factors (sorted alphabetically):\")\n",
    "for tf in sorted(unique_tfs):\n",
    "    print(f\"- {tf}\")\n",
    "print(\"\\nUnique cell types (sorted alphabetically):\")\n",
    "for cell in sorted(unique_celltypes):\n",
    "    print(f\"- {cell}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying UniProt for 171 transcription factors...\n",
      "Processing 1/171: AP-2alpha\n",
      "Processing 2/171: AP-2gamma\n",
      "Processing 3/171: ARID3A\n",
      "Processing 4/171: ATF1\n",
      "Processing 5/171: ATF2\n",
      "Processing 6/171: ATF3\n",
      "Processing 7/171: BAF155\n",
      "Processing 8/171: BAF170\n",
      "Processing 9/171: BATF\n",
      "Processing 10/171: BCL11A\n",
      "Processing 11/171: BCL3\n",
      "Processing 12/171: BCLAF1\n",
      "Processing 13/171: BDP1\n",
      "Processing 14/171: BHLHE40\n",
      "Processing 15/171: BRCA1\n",
      "Processing 16/171: BRF1\n",
      "Processing 17/171: BRF2\n",
      "Processing 18/171: Bach1\n",
      "Processing 19/171: Brg1\n",
      "Processing 20/171: CBX3\n",
      "Processing 21/171: CCNT2\n",
      "Processing 22/171: CEBPB\n",
      "Processing 23/171: CEBPD\n",
      "Processing 24/171: CHD1\n",
      "Processing 25/171: CHD2\n",
      "Processing 26/171: COREST\n",
      "Processing 27/171: CREB1\n",
      "Processing 28/171: CTCF\n",
      "Processing 29/171: CTCFL\n",
      "Processing 30/171: CtBP2\n",
      "Processing 31/171: E2F1\n",
      "Processing 32/171: E2F4\n",
      "Processing 33/171: E2F6\n",
      "Processing 34/171: EBF1\n",
      "Processing 35/171: ELF1\n",
      "Processing 36/171: ELK1\n",
      "Processing 37/171: ELK4\n",
      "Processing 38/171: ERRA\n",
      "Processing 39/171: ERalpha_a\n",
      "Processing 40/171: ETS1\n",
      "Processing 41/171: EZH2\n",
      "Processing 42/171: Egr-1\n",
      "Processing 43/171: FOSL1\n",
      "Processing 44/171: FOSL2\n",
      "Processing 45/171: FOXA1\n",
      "Processing 46/171: FOXA2\n",
      "Processing 47/171: FOXM1\n",
      "Processing 48/171: FOXP2\n",
      "Processing 49/171: GABP\n",
      "Processing 50/171: GATA-1\n",
      "Processing 51/171: GATA-2\n",
      "Processing 52/171: GATA2\n",
      "Processing 53/171: GATA3\n",
      "Processing 54/171: GR\n",
      "Processing 55/171: GRp20\n",
      "Processing 56/171: GTF2B\n",
      "Processing 57/171: GTF2F1\n",
      "Processing 58/171: HA-E2F1\n",
      "Processing 59/171: HDAC1\n",
      "Processing 60/171: HDAC2\n",
      "Processing 61/171: HDAC6\n",
      "Processing 62/171: HMGN3\n",
      "Processing 63/171: HNF4A\n",
      "Processing 64/171: HNF4G\n",
      "Processing 65/171: HSF1\n",
      "Processing 66/171: IKZF1\n",
      "Processing 67/171: IRF1\n",
      "Processing 68/171: IRF3\n",
      "Processing 69/171: IRF4\n",
      "Processing 70/171: Ini1\n",
      "Processing 71/171: JARID1A\n",
      "Processing 72/171: JunD\n",
      "Processing 73/171: KAP1\n",
      "Processing 74/171: MAZ\n",
      "Processing 75/171: MBD4\n",
      "Processing 76/171: MEF2A\n",
      "Processing 77/171: MEF2C\n",
      "Processing 78/171: MTA3\n",
      "Processing 79/171: MYBL2\n",
      "Processing 80/171: MafF\n",
      "Processing 81/171: MafK\n",
      "Processing 82/171: Max\n",
      "Processing 83/171: Mxi1\n",
      "Processing 84/171: NANOG\n",
      "Processing 85/171: NELFe\n",
      "Processing 86/171: NF-E2\n",
      "Processing 87/171: NF-YA\n",
      "Processing 88/171: NF-YB\n",
      "Processing 89/171: NFATC1\n",
      "Processing 90/171: NFIC\n",
      "Processing 91/171: NFKB\n",
      "Processing 92/171: NR2F2\n",
      "Processing 93/171: NRSF\n",
      "Processing 94/171: Nrf1\n",
      "Processing 95/171: PAX5-C20\n",
      "Processing 96/171: PAX5-N19\n",
      "Processing 97/171: PGC1A\n",
      "Processing 98/171: PHF8\n",
      "Processing 99/171: PLU1\n",
      "Processing 100/171: PML\n",
      "Processing 101/171: POU2F2\n",
      "Processing 102/171: POU5F1\n",
      "Processing 103/171: PRDM1\n",
      "Processing 104/171: PU.1\n",
      "Processing 105/171: Pbx3\n",
      "Processing 106/171: Pol2\n",
      "Processing 107/171: Pol2-4H8\n",
      "Processing 108/171: Pol3\n",
      "Processing 109/171: RBBP5\n",
      "Processing 110/171: RFX5\n",
      "Processing 111/171: RPC155\n",
      "Processing 112/171: RUNX3\n",
      "Processing 113/171: RXRA\n",
      "Processing 114/171: Rad21\n",
      "Processing 115/171: SAP30\n",
      "Processing 116/171: SETDB1\n",
      "Processing 117/171: SIN3A\n",
      "Processing 118/171: SIRT6\n",
      "Processing 119/171: SIX5\n",
      "Processing 120/171: SMC3\n",
      "Processing 121/171: SP1\n",
      "Processing 122/171: SP2\n",
      "Processing 123/171: SP4\n",
      "Processing 124/171: SPT20\n",
      "Processing 125/171: SREBP1\n",
      "Processing 126/171: SRF\n",
      "Processing 127/171: STAT1\n",
      "Processing 128/171: STAT2\n",
      "Processing 129/171: STAT3\n",
      "Processing 130/171: STAT5A\n",
      "Processing 131/171: SUZ12\n",
      "Processing 132/171: Sin3Ak-20\n",
      "Processing 133/171: TAF1\n",
      "Processing 134/171: TAF7\n",
      "Processing 135/171: TAL1\n",
      "Processing 136/171: TBLR1\n",
      "Processing 137/171: TBP\n",
      "Processing 138/171: TCF12\n",
      "Processing 139/171: TCF3\n",
      "Processing 140/171: TCF7L2\n",
      "Processing 141/171: TCF7L2_C9B9\n",
      "Processing 142/171: TEAD4\n",
      "Processing 143/171: TFIIIC-110\n",
      "Processing 144/171: THAP1\n",
      "Processing 145/171: TR4\n",
      "Processing 146/171: TRIM28\n",
      "Processing 147/171: UBF\n",
      "Processing 148/171: UBTF\n",
      "Processing 149/171: USF-1\n",
      "Processing 150/171: USF1\n",
      "Processing 151/171: USF2\n",
      "Processing 152/171: WHIP\n",
      "Processing 153/171: YY1\n",
      "Processing 154/171: ZBTB33\n",
      "Processing 155/171: ZBTB7A\n",
      "Processing 156/171: ZEB1\n",
      "Processing 157/171: ZKSCAN1\n",
      "Processing 158/171: ZNF217\n",
      "Processing 159/171: ZNF263\n",
      "Processing 160/171: ZNF274\n",
      "Processing 161/171: ZZZ3\n",
      "Processing 162/171: Znf143\n",
      "Processing 163/171: c-Fos\n",
      "Processing 164/171: c-Jun\n",
      "Processing 165/171: c-Myc\n",
      "Processing 166/171: eGFP-FOS\n",
      "Processing 167/171: eGFP-GATA2\n",
      "Processing 168/171: eGFP-HDAC8\n",
      "Processing 169/171: eGFP-JunB\n",
      "Processing 170/171: eGFP-JunD\n",
      "Processing 171/171: p300\n",
      "Mapping saved to /bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_uniprot_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Input file with TF names\n",
    "input_csv = '/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_celltype_list.csv'\n",
    "\n",
    "# Output file for TF to UniProt mapping\n",
    "output_csv = '/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_uniprot_mapping.csv'\n",
    "\n",
    "# Extract unique TF names from the CSV\n",
    "unique_tfs = set()\n",
    "with open(input_csv, 'r', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        if row:  # Make sure the row is not empty\n",
    "            unique_tfs.add(row[0])  # TF is in the first column\n",
    "\n",
    "# Function to query UniProt API\n",
    "def get_uniprot_id(tf_name):\n",
    "    # Base URL for UniProt API\n",
    "    base_url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "    \n",
    "    # Construct query\n",
    "    # Searching for human proteins with the name and filtering for reviewed entries\n",
    "    params = {\n",
    "        'query': f'({tf_name}) AND (organism_id:9606) AND (reviewed:true)',\n",
    "        'format': 'tsv',\n",
    "        'fields': 'accession,protein_name,gene_names'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            lines = response.text.strip().split('\\n')\n",
    "            if len(lines) > 1:  # Header + at least one result\n",
    "                # Return first result (accession, protein name, gene names)\n",
    "                parts = lines[1].split('\\t')\n",
    "                if len(parts) >= 3:\n",
    "                    return parts[0], parts[1], parts[2]\n",
    "        \n",
    "        # If no results or error, return None\n",
    "        return None, None, None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying UniProt for {tf_name}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Create a mapping of TF names to UniProt IDs\n",
    "tf_uniprot_map = {}\n",
    "count = 0\n",
    "total = len(unique_tfs)\n",
    "\n",
    "print(f\"Querying UniProt for {total} transcription factors...\")\n",
    "\n",
    "for tf in sorted(unique_tfs):\n",
    "    count += 1\n",
    "    print(f\"Processing {count}/{total}: {tf}\")\n",
    "    \n",
    "    # Query UniProt\n",
    "    uniprot_id, protein_name, gene_names = get_uniprot_id(tf)\n",
    "    \n",
    "    # Store in map\n",
    "    tf_uniprot_map[tf] = {\n",
    "        'uniprot_id': uniprot_id,\n",
    "        'protein_name': protein_name,\n",
    "        'gene_names': gene_names\n",
    "    }\n",
    "    \n",
    "    # Add a small delay to avoid hitting rate limits\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Write the mapping to CSV\n",
    "with open(output_csv, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Transcription Factor', 'UniProt ID', 'Protein Name', 'Gene Names'])\n",
    "    \n",
    "    for tf in sorted(tf_uniprot_map.keys()):\n",
    "        writer.writerow([\n",
    "            tf,\n",
    "            tf_uniprot_map[tf]['uniprot_id'] or 'Not found',\n",
    "            tf_uniprot_map[tf]['protein_name'] or 'Not found',\n",
    "            tf_uniprot_map[tf]['gene_names'] or 'Not found'\n",
    "        ])\n",
    "\n",
    "print(f\"Mapping saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique UniProt IDs: 161\n",
      "Number of transcription factors without UniProt IDs: 0\n",
      "Total number of transcription factors: 171\n",
      "\n",
      "Transcription factors without UniProt IDs:\n",
      "\n",
      "Percentage of TFs with UniProt IDs: 94.15%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to the UniProt mapping CSV file\n",
    "uniprot_mapping_file = '/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_uniprot_mapping.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(uniprot_mapping_file)\n",
    "\n",
    "# Count unique UniProt IDs (excluding 'Not found')\n",
    "unique_uniprot_ids = df[df['UniProt ID'] != 'Not found']['UniProt ID'].nunique()\n",
    "\n",
    "# Count NaN (entries where UniProt ID is 'Not found')\n",
    "nan_count = df[df['UniProt ID'] == 'Not found'].shape[0]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of unique UniProt IDs: {unique_uniprot_ids}\")\n",
    "print(f\"Number of transcription factors without UniProt IDs: {nan_count}\")\n",
    "print(f\"Total number of transcription factors: {df.shape[0]}\")\n",
    "\n",
    "# Optional: Print TFs without UniProt IDs\n",
    "print(\"\\nTranscription factors without UniProt IDs:\")\n",
    "for tf in df[df['UniProt ID'] == 'Not found']['Transcription Factor']:\n",
    "    print(f\"- {tf}\")\n",
    "\n",
    "# Optional: Calculate percentage of TFs with UniProt IDs\n",
    "percentage_with_uniprot = (unique_uniprot_ids / df.shape[0]) * 100\n",
    "print(f\"\\nPercentage of TFs with UniProt IDs: {percentage_with_uniprot:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Type Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcription Factor</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP-2alpha</td>\n",
       "      <td>HeLa-S3</td>\n",
       "      <td>wgEncodeAwgTfbsSydhHelas3Ap2alphaUniPk.narrowP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP-2gamma</td>\n",
       "      <td>HeLa-S3</td>\n",
       "      <td>wgEncodeAwgTfbsSydhHelas3Ap2gammaUniPk.narrowP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARID3A</td>\n",
       "      <td>HepG2</td>\n",
       "      <td>wgEncodeAwgTfbsSydhHepg2Arid3anb100279IggrabUn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARID3A</td>\n",
       "      <td>K562</td>\n",
       "      <td>wgEncodeAwgTfbsSydhK562Arid3asc8821IggrabUniPk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATF1</td>\n",
       "      <td>K562</td>\n",
       "      <td>wgEncodeAwgTfbsSydhK562Atf106325UniPk.narrowPe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transcription Factor Cell Type  \\\n",
       "0            AP-2alpha   HeLa-S3   \n",
       "1            AP-2gamma   HeLa-S3   \n",
       "2               ARID3A     HepG2   \n",
       "3               ARID3A      K562   \n",
       "4                 ATF1      K562   \n",
       "\n",
       "                                            Filename  \n",
       "0  wgEncodeAwgTfbsSydhHelas3Ap2alphaUniPk.narrowP...  \n",
       "1  wgEncodeAwgTfbsSydhHelas3Ap2gammaUniPk.narrowP...  \n",
       "2  wgEncodeAwgTfbsSydhHepg2Arid3anb100279IggrabUn...  \n",
       "3  wgEncodeAwgTfbsSydhK562Arid3asc8821IggrabUniPk...  \n",
       "4  wgEncodeAwgTfbsSydhK562Atf106325UniPk.narrowPe...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UniProt Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcription Factor</th>\n",
       "      <th>UniProt ID</th>\n",
       "      <th>Protein Name</th>\n",
       "      <th>Gene Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP-2alpha</td>\n",
       "      <td>P05549</td>\n",
       "      <td>Transcription factor AP-2-alpha (AP2-alpha) (A...</td>\n",
       "      <td>TFAP2A AP2TF TFAP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP-2gamma</td>\n",
       "      <td>Q92754</td>\n",
       "      <td>Transcription factor AP-2 gamma (AP2-gamma) (A...</td>\n",
       "      <td>TFAP2C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARID3A</td>\n",
       "      <td>Q99856</td>\n",
       "      <td>AT-rich interactive domain-containing protein ...</td>\n",
       "      <td>ARID3A DRIL1 DRIL3 DRX E2FBP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATF1</td>\n",
       "      <td>P18846</td>\n",
       "      <td>Cyclic AMP-dependent transcription factor ATF-...</td>\n",
       "      <td>ATF1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATF2</td>\n",
       "      <td>P15336</td>\n",
       "      <td>Cyclic AMP-dependent transcription factor ATF-...</td>\n",
       "      <td>ATF2 CREB2 CREBP1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transcription Factor UniProt ID  \\\n",
       "0            AP-2alpha     P05549   \n",
       "1            AP-2gamma     Q92754   \n",
       "2               ARID3A     Q99856   \n",
       "3                 ATF1     P18846   \n",
       "4                 ATF2     P15336   \n",
       "\n",
       "                                        Protein Name  \\\n",
       "0  Transcription factor AP-2-alpha (AP2-alpha) (A...   \n",
       "1  Transcription factor AP-2 gamma (AP2-gamma) (A...   \n",
       "2  AT-rich interactive domain-containing protein ...   \n",
       "3  Cyclic AMP-dependent transcription factor ATF-...   \n",
       "4  Cyclic AMP-dependent transcription factor ATF-...   \n",
       "\n",
       "                      Gene Names  \n",
       "0             TFAP2A AP2TF TFAP2  \n",
       "1                         TFAP2C  \n",
       "2  ARID3A DRIL1 DRIL3 DRX E2FBP1  \n",
       "3                           ATF1  \n",
       "4              ATF2 CREB2 CREBP1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcription Factor</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Filename</th>\n",
       "      <th>UniProt ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP-2alpha</td>\n",
       "      <td>HeLa-S3</td>\n",
       "      <td>wgEncodeAwgTfbsSydhHelas3Ap2alphaUniPk.narrowP...</td>\n",
       "      <td>P05549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP-2gamma</td>\n",
       "      <td>HeLa-S3</td>\n",
       "      <td>wgEncodeAwgTfbsSydhHelas3Ap2gammaUniPk.narrowP...</td>\n",
       "      <td>Q92754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARID3A</td>\n",
       "      <td>HepG2</td>\n",
       "      <td>wgEncodeAwgTfbsSydhHepg2Arid3anb100279IggrabUn...</td>\n",
       "      <td>Q99856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARID3A</td>\n",
       "      <td>K562</td>\n",
       "      <td>wgEncodeAwgTfbsSydhK562Arid3asc8821IggrabUniPk...</td>\n",
       "      <td>Q99856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATF1</td>\n",
       "      <td>K562</td>\n",
       "      <td>wgEncodeAwgTfbsSydhK562Atf106325UniPk.narrowPe...</td>\n",
       "      <td>P18846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transcription Factor Cell Type  \\\n",
       "0            AP-2alpha   HeLa-S3   \n",
       "1            AP-2gamma   HeLa-S3   \n",
       "2               ARID3A     HepG2   \n",
       "3               ARID3A      K562   \n",
       "4                 ATF1      K562   \n",
       "\n",
       "                                            Filename UniProt ID  \n",
       "0  wgEncodeAwgTfbsSydhHelas3Ap2alphaUniPk.narrowP...     P05549  \n",
       "1  wgEncodeAwgTfbsSydhHelas3Ap2gammaUniPk.narrowP...     Q92754  \n",
       "2  wgEncodeAwgTfbsSydhHepg2Arid3anb100279IggrabUn...     Q99856  \n",
       "3  wgEncodeAwgTfbsSydhK562Arid3asc8821IggrabUniPk...     Q99856  \n",
       "4  wgEncodeAwgTfbsSydhK562Atf106325UniPk.narrowPe...     P18846  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved merged data to 'merged_transcription_factors.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import required library\n",
    "import pandas as pd\n",
    "\n",
    "# Load both datasets\n",
    "cell_type_df = pd.read_csv(\"/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_celltype_list.csv\")  # Contains: Transcription Factor, Cell Type, Filename\n",
    "uniprot_df = pd.read_csv(\"/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_uniprot_mapping.csv\")      # Contains: Transcription Factor, UniProt ID, Protein Name, Gene Names\n",
    "\n",
    "# Display the first few rows of each dataset to verify\n",
    "print(\"Cell Type Data:\")\n",
    "display(cell_type_df.head())\n",
    "\n",
    "print(\"\\nUniProt Data:\")\n",
    "display(uniprot_df.head())\n",
    "\n",
    "# Merge the datasets on 'Transcription Factor'\n",
    "merged_df = pd.merge(\n",
    "    cell_type_df,\n",
    "    uniprot_df[['Transcription Factor', 'UniProt ID']],  # Only take needed columns from uniprot data\n",
    "    on='Transcription Factor',\n",
    "    how='left'  # Keep all rows from cell_type_df even if no match\n",
    ")\n",
    "\n",
    "# Select only the columns we want in the final output\n",
    "final_df = merged_df[['Transcription Factor', 'Cell Type', 'Filename', 'UniProt ID']]\n",
    "\n",
    "# Display the merged result\n",
    "print(\"\\nMerged Data:\")\n",
    "display(final_df.head())\n",
    "\n",
    "# Save to file if needed\n",
    "final_df.to_csv(\"/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_celltype_list_uniprotID.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in final data: 690\n",
      "Entries with UniProt IDs: 690\n",
      "Entries missing UniProt IDs: 0\n",
      "\n",
      "All entries have UniProt IDs!\n",
      "\n",
      "Sample of final merged data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transcription Factor</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Filename</th>\n",
       "      <th>UniProt ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP-2alpha</td>\n",
       "      <td>HeLa-S3</td>\n",
       "      <td>wgEncodeAwgTfbsSydhHelas3Ap2alphaUniPk.narrowP...</td>\n",
       "      <td>P05549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP-2gamma</td>\n",
       "      <td>HeLa-S3</td>\n",
       "      <td>wgEncodeAwgTfbsSydhHelas3Ap2gammaUniPk.narrowP...</td>\n",
       "      <td>Q92754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARID3A</td>\n",
       "      <td>HepG2</td>\n",
       "      <td>wgEncodeAwgTfbsSydhHepg2Arid3anb100279IggrabUn...</td>\n",
       "      <td>Q99856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARID3A</td>\n",
       "      <td>K562</td>\n",
       "      <td>wgEncodeAwgTfbsSydhK562Arid3asc8821IggrabUniPk...</td>\n",
       "      <td>Q99856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATF1</td>\n",
       "      <td>K562</td>\n",
       "      <td>wgEncodeAwgTfbsSydhK562Atf106325UniPk.narrowPe...</td>\n",
       "      <td>P18846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transcription Factor Cell Type  \\\n",
       "0            AP-2alpha   HeLa-S3   \n",
       "1            AP-2gamma   HeLa-S3   \n",
       "2               ARID3A     HepG2   \n",
       "3               ARID3A      K562   \n",
       "4                 ATF1      K562   \n",
       "\n",
       "                                            Filename UniProt ID  \n",
       "0  wgEncodeAwgTfbsSydhHelas3Ap2alphaUniPk.narrowP...     P05549  \n",
       "1  wgEncodeAwgTfbsSydhHelas3Ap2gammaUniPk.narrowP...     Q92754  \n",
       "2  wgEncodeAwgTfbsSydhHepg2Arid3anb100279IggrabUn...     Q99856  \n",
       "3  wgEncodeAwgTfbsSydhK562Arid3asc8821IggrabUniPk...     Q99856  \n",
       "4  wgEncodeAwgTfbsSydhK562Atf106325UniPk.narrowPe...     P18846  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved merged data to 'merged_transcription_factors.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import required library\n",
    "import pandas as pd\n",
    "\n",
    "# Load both datasets\n",
    "cell_type_df = pd.read_csv(\"/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_celltype_list.csv\")  # Contains: Transcription Factor, Cell Type, Filename\n",
    "uniprot_df = pd.read_csv(\"/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_uniprot_mapping.csv\")      # Contains: Transcription Factor, UniProt ID, Protein Name, Gene Names\n",
    "\n",
    "\n",
    "# Merge the datasets\n",
    "merged_df = pd.merge(\n",
    "    cell_type_df,\n",
    "    uniprot_df[['Transcription Factor', 'UniProt ID']],\n",
    "    on='Transcription Factor',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create final dataframe with selected columns\n",
    "final_df = merged_df[['Transcription Factor', 'Cell Type', 'Filename', 'UniProt ID']]\n",
    "\n",
    "# Check for missing UniProt IDs\n",
    "missing_uniprot = final_df[final_df['UniProt ID'].isna()]\n",
    "\n",
    "print(f\"Total entries in final data: {len(final_df)}\")\n",
    "print(f\"Entries with UniProt IDs: {len(final_df) - len(missing_uniprot)}\")\n",
    "print(f\"Entries missing UniProt IDs: {len(missing_uniprot)}\")\n",
    "\n",
    "if not missing_uniprot.empty:\n",
    "    print(\"\\nEntries missing UniProt IDs:\")\n",
    "    display(missing_uniprot)\n",
    "    \n",
    "    print(\"\\nSummary of missing IDs by Cell Type:\")\n",
    "    display(missing_uniprot['Cell Type'].value_counts())\n",
    "else:\n",
    "    print(\"\\nAll entries have UniProt IDs!\")\n",
    "\n",
    "# Display final merged data sample\n",
    "print(\"\\nSample of final merged data:\")\n",
    "display(final_df.head())\n",
    "\n",
    "# Save to file\n",
    "final_df.to_csv(\"/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_celltype_list_uniprotID.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "uniprot_ids = [\"P00750\", \"P12345\"]  # Your UniProt IDs\n",
    "base_url = \"http://jaspar.genereg.net/api/v1/matrix/\"\n",
    "\n",
    "for uid in uniprot_ids:\n",
    "    response = requests.get(f\"{base_url}?uniprot={uid}&format=json\")\n",
    "    if response.status_code == 200:\n",
    "        with open(f\"{uid}_pwm.json\", \"w\") as f:\n",
    "            f.write(response.text)\n",
    "    else:\n",
    "        print(f\"Failed for {uid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cell types:\n",
      "A549\n",
      "AG04449\n",
      "AG04450\n",
      "AG09309\n",
      "AG09319\n",
      "AG10803\n",
      "AoAF\n",
      "BE2_C\n",
      "BJ\n",
      "Caco-2\n",
      "Dnd41\n",
      "ECC-1\n",
      "Fibrobl\n",
      "GM06990\n",
      "GM08714\n",
      "GM10847\n",
      "GM12801\n",
      "GM12864\n",
      "GM12865\n",
      "GM12872\n",
      "GM12873\n",
      "GM12874\n",
      "GM12875\n",
      "GM12878\n",
      "GM12891\n",
      "GM12892\n",
      "GM15510\n",
      "GM18505\n",
      "GM18526\n",
      "GM18951\n",
      "GM19099\n",
      "GM19193\n",
      "GM19238\n",
      "GM19239\n",
      "GM19240\n",
      "Gliobla\n",
      "H1-hESC\n",
      "HA-sp\n",
      "HAc\n",
      "HBMEC\n",
      "HCFaa\n",
      "HCM\n",
      "HCPEpiC\n",
      "HCT-116\n",
      "HEEpiC\n",
      "HEK293\n",
      "HEK293-T-REx\n",
      "HFF\n",
      "HFF-Myc\n",
      "HL-60\n",
      "HMEC\n",
      "HMF\n",
      "HPAF\n",
      "HPF\n",
      "HRE\n",
      "HRPEpiC\n",
      "HSMM\n",
      "HSMMtube\n",
      "HUVEC\n",
      "HVMF\n",
      "HeLa-S3\n",
      "HepG2\n",
      "IMR90\n",
      "K562\n",
      "MCF-7\n",
      "MCF10A-Er-Src\n",
      "NB4\n",
      "NH-A\n",
      "NHDF-Ad\n",
      "NHDF-neo\n",
      "NHEK\n",
      "NHLF\n",
      "NT2-D1\n",
      "Osteobl\n",
      "PANC-1\n",
      "PBDE\n",
      "PBDEFetal\n",
      "PFSK-1\n",
      "ProgFib\n",
      "RPTEC\n",
      "Raji\n",
      "SAEC\n",
      "SH-SY5Y\n",
      "SK-N-MC\n",
      "SK-N-SH\n",
      "SK-N-SH_RA\n",
      "T-47D\n",
      "U2OS\n",
      "U87\n",
      "WERI-Rb-1\n",
      "WI-38\n"
     ]
    }
   ],
   "source": [
    "#unique cell type \n",
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file = '/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_celltype_list.csv'\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Get unique cell types\n",
    "unique_cell_types = sorted(df['CellType'].unique())\n",
    "\n",
    "# Print the unique cell types\n",
    "print(\"Unique cell types:\")\n",
    "for cell_type in unique_cell_types:\n",
    "    print(cell_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 91 unique cell types to /bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/unique_cell_types.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the file (choose .csv or .xlsx)\n",
    "input_file = '/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/tf_celltype_list.csv'  # or 'tf_celltype_list.xlsx'\n",
    "df = pd.read_csv(input_file) if input_file.endswith('.csv') else pd.read_excel(input_file)\n",
    "\n",
    "# Extract unique cell types from the 'CellType' column\n",
    "unique_cell_types = sorted(df['CellType'].dropna().unique())\n",
    "\n",
    "# Save to a new file\n",
    "output_file = '/bml/shreya/TF_binding_site/dataset_test/DEEPSEA_dataextraction/data/unique_cell_types.txt'\n",
    "with open(output_file, 'w') as f:\n",
    "    for cell_type in unique_cell_types:\n",
    "        f.write(f\"{cell_type}\\n\")\n",
    "\n",
    "print(f\"Saved {len(unique_cell_types)} unique cell types to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BertEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
